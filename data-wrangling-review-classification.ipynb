{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4tE3nhbp235"
   },
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c10a16d6-b7b9-4535-be11-2e7c3e06819b"
   },
   "outputs": [],
   "source": [
    "#!pip install spark-nlp\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#create Spark session\n",
    "spark = SparkSession.builder.appName('classification').getOrCreate()\n",
    "\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'), \n",
    "                                        ('spark.app.name', 'review-classification'), \n",
    "                                        ('spark.executor.cores', '5'), \n",
    "                                        ('spark.cores.max', '4'), \n",
    "                                        ('spark.driver.memory','8g')])\n",
    "\n",
    "#print spark configuration settings\n",
    "spark.sparkContext.getConf().getAll()\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"CORRECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d49241c-0539-4084-ad63-00f36f332106"
   },
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "df = spark.read.json(\"gs://bdprojectfinal/Clothing_Shoes_and_Jewelry.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4a6f676-d819-4dba-8ff7-9e2f2de1210f"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.caseSensitive\", \"true\")\n",
    "meta=spark.read.json('gs://bdprojectfinal/meta_Clothing_Shoes_and_Jewelry.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f08d27e0-c3a9-418a-8c12-59a8fc4e37cd"
   },
   "outputs": [],
   "source": [
    "meta=meta.select(\"brand\",\"asin\",\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6920186-fe51-4706-8fa5-e7228376a1e0"
   },
   "outputs": [],
   "source": [
    "meta.createOrReplaceTempView('meta')\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2194fd2-a20a-485f-acb4-08dcc0d0b8aa"
   },
   "outputs": [],
   "source": [
    "df=df.withColumn(\"reviewTime\", f.to_timestamp('reviewTime','MM dd, yyyy'))\\\n",
    "    .withColumn(\"Year\", f.year(\"reviewTime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "813707cd-d2da-49f6-9f53-6ded1608c006"
   },
   "outputs": [],
   "source": [
    "review_count_full=spark.sql('''select \n",
    "asin,\n",
    "count(*) as review_count\n",
    "from df\n",
    "group by\n",
    "asin\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "285a9622-35ea-4cf6-8c1e-8e0ade4282b6"
   },
   "outputs": [],
   "source": [
    "rc_df=review_count_full.toPandas()\n",
    "\n",
    "rc_df.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baabc40d-be96-4ac8-b1cc-d821fb87be63"
   },
   "outputs": [],
   "source": [
    "#creative view\n",
    "df.createOrReplaceTempView('df')\n",
    "\n",
    "review_count=spark.sql('''select \n",
    "asin,\n",
    "count(*)\n",
    "from df\n",
    "group by\n",
    "asin\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44a8e518-13e1-40fb-bc68-57cee14599c9"
   },
   "outputs": [],
   "source": [
    "rc_df=review_count.toPandas()\n",
    "\n",
    "rc_df.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the products with over 10 review counts with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b212e55-fa0e-417d-9998-c902e6ddc62b"
   },
   "outputs": [],
   "source": [
    "df_full=spark.sql('''\n",
    "with cte as (\n",
    "select \n",
    "asin,\n",
    "count(*) as review_count\n",
    "from df\n",
    "group by\n",
    "asin\n",
    "),\n",
    "\n",
    "fil as (\n",
    "select \n",
    "asin\n",
    "from cte\n",
    "where review_count>10\n",
    "),\n",
    "\n",
    "cte3 as (\n",
    "select\n",
    "reviewerID,\n",
    "count(*) as reviewer_count\n",
    "from df\n",
    "group by reviewerID\n",
    "),\n",
    "\n",
    "cte2 as (select \n",
    "Year,\n",
    "overall,\n",
    "reviewText,\n",
    "reviewTime,\n",
    "reviewerID,\n",
    "reviewerName,\n",
    "unixReviewTime,\n",
    "verified,\n",
    "vote,\n",
    "asin\n",
    "from df\n",
    "where\n",
    "asin in (select asin from fil))\n",
    "\n",
    "select \n",
    "d.Year,\n",
    "d.overall,\n",
    "d.reviewText,\n",
    "d.reviewTime,\n",
    "d.reviewerID,\n",
    "d.reviewerName,\n",
    "d.unixReviewTime,\n",
    "d.verified,\n",
    "d.vote,\n",
    "d.asin,\n",
    "r.reviewer_count,\n",
    "m.brand,\n",
    "m.price\n",
    "from \n",
    "cte2 d inner join cte3 r on d.reviewerID=r.reviewerID\n",
    "inner join meta m on d.asin=m.asin\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a35924cb-dc3e-43ad-9b1b-dc749e266046"
   },
   "outputs": [],
   "source": [
    "df_full.createOrReplaceTempView('df_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6a7bdbb-fe50-41ed-8fde-115fc998929b"
   },
   "outputs": [],
   "source": [
    "df_full_reviewer=spark.sql('''\n",
    "with cte as (\n",
    "select\n",
    "reviewerID,\n",
    "count(*) as reviewer_count\n",
    "from df\n",
    "group by reviewerID\n",
    ")\n",
    "\n",
    "select \n",
    "d.Year,\n",
    "d.overall,\n",
    "d.reviewText,\n",
    "d.reviewTime,\n",
    "d.reviewerID,\n",
    "d.reviewerName,\n",
    "d.unixReviewTime,\n",
    "d.verified,\n",
    "d.vote,\n",
    "d.asin,\n",
    "reviewer.reviewer_count\n",
    "from df_full d left join cte reviewer on d.reviewerID = reviewer.reviewerID\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c18aa792-8e1f-4ee0-ad46-81b5a196462b"
   },
   "outputs": [],
   "source": [
    "df_use.write.json(\"gs://bdprojectfinal/df_full_feature_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39f583f7-cd88-4d53-af07-5962b7ec2be7"
   },
   "source": [
    "## Spark NLP set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ee1857d6-059f-4eca-b221-795ca20bb0c8"
   },
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "import sparknlp\n",
    "#Start a Spark session using Spark NLP\n",
    "spark=sparknlp.start()\n",
    "\n",
    " spark = SparkSession.builder \\\n",
    "     .appName(\"reviewclassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "conf = spark.sparkContext._conf.setAll([(\"spark.driver.memory\",\"4G\"),\n",
    "                                        (\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.0.3\"),\n",
    "                                       ('spark.executor.cores', '5'),\n",
    "                                        ('spark.executor.memory', '4G')\n",
    "                                       ])\n",
    "SparkSession.builder.config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "833b4209-7c7c-4251-b313-f5ffa37ba452"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator# Convert text column to nlp file\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.context import SparkContext\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC,LogisticRegression,FMClassifier,RandomForestClassifier,LinearSVC,GBTClassifier\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b4cfe630-5135-4b51-b5e3-88313ab5a2f6"
   },
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "df = spark.read.json(\"gs://bdprojectfinal/df_full_feature_data/*.json\")\n",
    "#convert voting to binary labels\n",
    "df = df.withColumn(\n",
    "    'label',\n",
    "    f.when(f.col(\"vote\")>0, 1)\\\n",
    "    .otherwise(0)\n",
    ")\n",
    "#split into Train and Test\n",
    "Train, Test = df.randomSplit([0.8, 0.2], seed = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6243e941-8563-410c-b657-0b9249e8c1ed"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_report(prediction_result):\n",
    "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    evaluator = MulticlassClassificationEvaluator()\n",
    "    acc=evaluator.evaluate(prediction_result,{evaluator.metricName: \"accuracy\"})\n",
    "    class1=prediction_result.where(f.col('label')==1)\n",
    "    f1_class1=evaluator.evaluate(class1,{evaluator.metricName: \"f1\"})\n",
    "    class0=prediction_result.where(f.col('label')==0)\n",
    "    f1_class0=evaluator.evaluate(class0,{evaluator.metricName: \"f1\"}) \n",
    "    output = pd.DataFrame(np.array([[acc,f1_class1,f1_class0]]),\n",
    "                   columns=['accuracy', 'f1_class1', 'f1_class0'])\n",
    "    return output\n",
    "\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf(\"long\")\n",
    "def num_nonzeros(v):\n",
    "    return v.numNonzeros()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc9b90f8-5f09-4225-b565-2cfe90653636"
   },
   "source": [
    "## TF-IDF embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "201d36b2-b5d0-44d7-9930-e482d08ac96c"
   },
   "outputs": [],
   "source": [
    "#define pipeline for data processing\n",
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"reviewText\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "      .setInputCols([\"cleanTokens\"]) \\\n",
    "      .setOutputCol(\"stem\")\n",
    "finisher = Finisher() \\\n",
    "      .setInputCols([\"stem\"]) \\\n",
    "      .setOutputCols([\"token_features\"]) \\\n",
    "      .setOutputAsArray(True) \\\n",
    "      .setCleanAnnotations(False)\n",
    "hashingTF = HashingTF(inputCol=\"token_features\", \n",
    "                      outputCol=\"rawFeatures\", \n",
    "                      numFeatures=10000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", \n",
    "          outputCol=\"features\", \n",
    "          minDocFreq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2de84e27-1c8b-43db-8c61-e66923eb2577"
   },
   "outputs": [],
   "source": [
    "#define TF-IDF pipeline\n",
    "nlp_pipeline_tf = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            stemmer, \n",
    "            finisher,\n",
    "            hashingTF,\n",
    "            idf])\n",
    "#process training dataset\n",
    "nlp_model_tf = nlp_pipeline_tf.fit(Train)\n",
    "#transform train and test dataset\n",
    "Train  = nlp_model_tf.transform(Train)\n",
    "Test = nlp_model_tf.transform(Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3d2d866-8cb9-4572-b242-c2f6c26cee6a",
    "tags": []
   },
   "source": [
    "## TF-IDF with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c92f90d-6ec9-4e4b-9e3d-eea58967ec94"
   },
   "outputs": [],
   "source": [
    "#initiate logistic regression with weight\n",
    "lr = LogisticRegression(featuresCol = 'features', \n",
    "                        labelCol = 'label', \n",
    "                        maxIter=10)\n",
    "#fit model\n",
    "lrModel = lr.fit(Train)\n",
    "#predict on test data\n",
    "predictions_tf = lrModel.transform(Test)\n",
    "result=evaluation_report(predictions_tf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "563070a3-4100-4655-b323-80a8e440765f"
   },
   "source": [
    "## Random Forest with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daa8ab29-d7ef-4f89-bf6e-8d498435cd78"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# add training dataset\n",
    "rfModel = rf.fit(Train)\n",
    "predictions_rf = rfModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3ace1d7-6806-4602-95e3-513478cedc05"
   },
   "outputs": [],
   "source": [
    "result=evaluation_report(predictions_rf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "459c9c53-17bb-41e3-b40d-6a3e79dd6472"
   },
   "source": [
    "## Naive Bayes with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ac520bf-91ec-423d-b54d-db31ff5b2612"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(labelCol=\"label\", \\\n",
    "                featuresCol=\"features\", \\\n",
    "                smoothing=1.0,\n",
    "                modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "nbModel = nb.fit(Train)\n",
    "\n",
    "# select example rows to display.\n",
    "prediction_nb = nbModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf4611f1-3024-4ba4-8210-98635ee724b8"
   },
   "outputs": [],
   "source": [
    "result=evaluation_report(predictions_nb)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"label\", \n",
    "                            featuresCol=\"feature\")\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(Train)\n",
    "\n",
    "predictions=lsvcModel.transform(Test)\n",
    "result=evaluation_report(predictions)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FMClassifier with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import FMClassifier\n",
    "fm = FMClassifier(featuresCol=\"features-Bert\",labelCol=\"label\",stepSize=0.01)\n",
    "# train the model\n",
    "model_fm = fm.fit(Train)\n",
    "# select example rows to display.\n",
    "prediction = model_fm.transform(Test)\n",
    "result=evaluation_report(prediction)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weight to modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balancingRatio = Train.filter(f.col('label') == 1).count() / Train.count()\n",
    "\n",
    "Train = Train.withColumn(\n",
    "    'weight1',\n",
    "    f.when(f.col(\"label\")==1, (1+balancingRatio))\\\n",
    "    .otherwise(1-balancingRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c92f90d-6ec9-4e4b-9e3d-eea58967ec94"
   },
   "outputs": [],
   "source": [
    "#initiate logistic regression with weight\n",
    "lr = LogisticRegression(featuresCol = 'features', \n",
    "                        labelCol = 'label', \n",
    "                        weightCol=\"weight1\",\n",
    "                        maxIter=10)\n",
    "#fit model\n",
    "lrModel = lr.fit(Train)\n",
    "#predict on test data\n",
    "predictions_tf = lrModel.transform(Test)\n",
    "result=evaluation_report(predictions_tf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "563070a3-4100-4655-b323-80a8e440765f"
   },
   "source": [
    "## Random Forest with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daa8ab29-d7ef-4f89-bf6e-8d498435cd78"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            weightCol=\"weight1\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# add training dataset\n",
    "rfModel = rf.fit(Train)\n",
    "predictions_rf = rfModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3ace1d7-6806-4602-95e3-513478cedc05"
   },
   "outputs": [],
   "source": [
    "result=evaluation_report(predictions_rf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "459c9c53-17bb-41e3-b40d-6a3e79dd6472"
   },
   "source": [
    "## Naive Bayes with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ac520bf-91ec-423d-b54d-db31ff5b2612"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(labelCol=\"label\", \\\n",
    "                featuresCol=\"features\", \\\n",
    "                weightCol=\"weight1\",\n",
    "                smoothing=1.0,\n",
    "                modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "nbModel = nb.fit(Train)\n",
    "\n",
    "# select example rows to display.\n",
    "prediction_nb = nbModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf4611f1-3024-4ba4-8210-98635ee724b8"
   },
   "outputs": [],
   "source": [
    "result=evaluation_report(predictions_nb)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"label\", weightCol=\"weight1\",\n",
    "                            featuresCol=\"feature\")\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(Train)\n",
    "\n",
    "predictions=lsvcModel.transform(Test)\n",
    "result=evaluation_report(predictions)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FMClassifier with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import FMClassifier\n",
    "fm = FMClassifier(featuresCol=\"features-Bert\",labelCol=\"label\",weightCol=\"weight1\",stepSize=0.01)\n",
    "# train the model\n",
    "model_fm = fm.fit(Train)\n",
    "# select example rows to display.\n",
    "prediction = model_fm.transform(Test)\n",
    "result=evaluation_report(prediction)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFShGFjcILjs"
   },
   "source": [
    "## Glove embedding and re-balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_4oMD4AIO1Q",
    "outputId": "a513418a-2663-4691-bf70-9553dd2496fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"reviewText\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "    \n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
    "      .setInputCols([\"document\",'cleanTokens'])\\\n",
    "      .setOutputCol(\"embeddings\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "      .setOutputCol(\"sentence_embeddings\") \\\n",
    "      .setPoolingStrategy(\"AVERAGE\")\n",
    "    \n",
    "embeddings_finisher = EmbeddingsFinisher() \\\n",
    "      .setInputCols([\"sentence_embeddings\"]) \\\n",
    "      .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
    "      .setOutputAsVector(True)\\\n",
    "      .setCleanAnnotations(False)\n",
    "\n",
    "nlp_pipeline_w = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            glove_embeddings,\n",
    "            embeddingsSentence,\n",
    "            embeddings_finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "brWwvkHAISHn"
   },
   "outputs": [],
   "source": [
    "nlp_model_w= nlp_pipeline_w.fit(Train)\n",
    "\n",
    "Train= nlp_model_w.transform(Train)\n",
    "\n",
    "Train= Train.withColumn(\"GloVe-features\", explode(Train.finished_sentence_embeddings))\n",
    "\n",
    "Test= nlp_model_w.transform(Test)\n",
    "\n",
    "Test= Test.withColumn(\"GloVe-features\", explode(Test.finished_sentence_embeddings))\n",
    "\n",
    "Train=Train.drop('cleanTokens','document','normalized','rawFeatures','stem','token','token_features','finished_sentence_embeddings')\n",
    "Test=Test.drop('cleanTokens','document','normalized','rawFeatures','stem','token','token_features','finished_sentence_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6ceb708-509e-4d63-a00d-143cbc5a7c88"
   },
   "source": [
    "## Bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86a7c840-6f09-4f09-94f0-8676bb4a94de",
    "outputId": "42997f7f-ad0d-486c-ffc9-fce949418762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "#add new component\n",
    "bert_embeddings = BertEmbeddings\\\n",
    "      .pretrained('bert_base_cased', 'en') \\\n",
    "      .setInputCols([\"document\",'cleanTokens'])\\\n",
    "      .setOutputCol(\"bert\")\\\n",
    "      .setCaseSensitive(False)\\\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "      .setInputCols([\"document\", \"bert\"]) \\\n",
    "      .setOutputCol(\"sentence_embeddings\") \\\n",
    "      .setPoolingStrategy(\"AVERAGE\")\n",
    "    \n",
    "embeddings_finisher = EmbeddingsFinisher() \\\n",
    "      .setInputCols([\"sentence_embeddings\"]) \\\n",
    "      .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
    "      .setOutputAsVector(True)\\\n",
    "      .setCleanAnnotations(False)\n",
    "#create new pipeline\n",
    "nlp_pipeline_bert = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            bert_embeddings,\n",
    "            embeddingsSentence,\n",
    "            embeddings_finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48236be6-e29d-4ef0-9528-b71e535cba2e",
    "outputId": "b6f66c9f-8be8-40ae-c8f5-4ca9df72a6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_done\n"
     ]
    }
   ],
   "source": [
    "#create new processor for raw data\n",
    "Train = nlp_pipeline_bert.fit(Train).transform(Train)\n",
    "print('train_done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeb723c7-9bea-49be-9e75-c85a93149794",
    "outputId": "939a1394-03d8-4cb6-ff02-b2914670637c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_done\n"
     ]
    }
   ],
   "source": [
    "#process test data\n",
    "Test = nlp_pipeline_bert.fit(Train).transform(Test)\n",
    "print('test_done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=Train.drop('cleanTokens','document','normalized','rawFeatures','stem','token','token_features')\n",
    "Test=Test.drop('cleanTokens','document','normalized','rawFeatures','stem','token','token_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd_YnZNSEyp6"
   },
   "source": [
    "## Saving/Read Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = df.filter(f.col('label') == 1).count() / df.filter(f.col('label') == 0).count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process balanced dataset\n",
    "percentage=670054/7418313\n",
    "df=df.sampleBy(\"label\",\n",
    "               fractions={\n",
    "                   1:1,\n",
    "                   0:percentage},\n",
    "               seed=3\n",
    "               )\n",
    "Train, Test = df.randomSplit([0.8, 0.2], seed = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = Train.where(num_nonzeros(\"features\") != 0)\n",
    "Test = Test.where(num_nonzeros(\"features\") != 0)\n",
    "\n",
    "Train.write.json('gs://bdprojectfinal/train_multiple')\n",
    "Test.write.json('gs://bdprojectfinal/test_multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=spark.read.json('gs://bdprojectfinal/train_multiple/*.json')\n",
    "Test=spark.read.json('gs://bdprojectfinal/test_multiple/*.json')\n",
    "\n",
    "Train = Train.withColumn(\n",
    "    \"features-Bert\", \n",
    "    list_to_vector_udf(Train['features-Bert.values'])\n",
    ")\n",
    "\n",
    "Test = Test.withColumn(\n",
    "    \"features-Bert\", \n",
    "    list_to_vector_udf(Test['features-Bert.values'])\n",
    ")\n",
    "\n",
    "Train = Train.withColumn(\n",
    "    \"features-GloVe\", \n",
    "    list_to_vector_udf(Train['features-GloVe.values'])\n",
    ")\n",
    "\n",
    "Test = Test.withColumn(\n",
    "    \"features-GloVe\", \n",
    "    list_to_vector_udf(Test['features-GloVe.values'])\n",
    ")\n",
    "\n",
    "Train = Train.where(num_nonzeros(\"features-GloVe\") != 0)\n",
    "Test = Test.where(num_nonzeros(\"features-GloVe\") != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-fitting to TFIDF feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3d2d866-8cb9-4572-b242-c2f6c26cee6a",
    "tags": []
   },
   "source": [
    "## TF-IDF with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c92f90d-6ec9-4e4b-9e3d-eea58967ec94"
   },
   "outputs": [],
   "source": [
    "#initiate logistic regression with weight\n",
    "lr = LogisticRegression(featuresCol = 'features', \n",
    "                        labelCol = 'label', \n",
    "                        maxIter=10)\n",
    "#fit model\n",
    "lrModel = lr.fit(Train)\n",
    "#predict on test data\n",
    "predictions_tf = lrModel.transform(Test)\n",
    "result=evaluation_report(predictions_tf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "563070a3-4100-4655-b323-80a8e440765f"
   },
   "source": [
    "## Random Forest with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daa8ab29-d7ef-4f89-bf6e-8d498435cd78"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# add training dataset\n",
    "rfModel = rf.fit(Train)\n",
    "predictions_rf = rfModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3ace1d7-6806-4602-95e3-513478cedc05"
   },
   "outputs": [],
   "source": [
    "result=evaluation_report(predictions_rf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "459c9c53-17bb-41e3-b40d-6a3e79dd6472"
   },
   "source": [
    "## Naive Bayes with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ac520bf-91ec-423d-b54d-db31ff5b2612"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(labelCol=\"label\", \\\n",
    "                featuresCol=\"features\", \\\n",
    "                smoothing=1.0,\n",
    "                modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "nbModel = nb.fit(Train)\n",
    "\n",
    "# select example rows to display.\n",
    "prediction_nb = nbModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf4611f1-3024-4ba4-8210-98635ee724b8"
   },
   "outputs": [],
   "source": [
    "result=evaluation_report(predictions_nb)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"label\", \n",
    "                            featuresCol=\"feature\")\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(Train)\n",
    "\n",
    "predictions=lsvcModel.transform(Test)\n",
    "result=evaluation_report(predictions)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FMClassifier with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import FMClassifier\n",
    "fm = FMClassifier(featuresCol=\"features-Bert\",labelCol=\"label\",stepSize=0.01)\n",
    "# train the model\n",
    "model_fm = fm.fit(Train)\n",
    "# select example rows to display.\n",
    "prediction = model_fm.transform(Test)\n",
    "result=evaluation_report(prediction)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced dataset w/ Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate logistic regression with weight\n",
    "lr = LogisticRegression(featuresCol = 'features-Bert', \n",
    "                        labelCol = 'label', \n",
    "                        maxIter=10)\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features-Bert\", \\\n",
    "                            numTrees = 50, \\\n",
    "                            maxDepth = 3, \\\n",
    "                            maxBins = 32)\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"label\", \n",
    "                            featuresCol=\"features-Bert\")\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features-Bert\", maxIter=5)\n",
    "fm = FMClassifier(featuresCol=\"features-Bert\",labelCol=\"label\",stepSize=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=pd.DataFrame(columns=['accuracy','f1_class1','f1_class0'])\n",
    "for i in [lr,rf,lsvc,gbt,fm]:\n",
    "    model = i.fit(Train)\n",
    "    prediction = model.transform(Test)\n",
    "    results=evaluation_report(prediction)\n",
    "    summary=summary.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.713075</td>\n",
       "      <td>0.825616</td>\n",
       "      <td>0.839332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.701584</td>\n",
       "      <td>0.793902</td>\n",
       "      <td>0.853867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710358</td>\n",
       "      <td>0.811960</td>\n",
       "      <td>0.848798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.694555</td>\n",
       "      <td>0.793667</td>\n",
       "      <td>0.844767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.715667</td>\n",
       "      <td>0.829144</td>\n",
       "      <td>0.839365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0  0.713075   0.825616   0.839332\n",
       "0  0.701584   0.793902   0.853867\n",
       "0  0.710358   0.811960   0.848798\n",
       "0  0.694555   0.793667   0.844767\n",
       "0  0.715667   0.829144   0.839365"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").setHandleInvalid(\"keep\").fit(Train) for column in list(['price','brand','asin','reviewerID'])]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "pipelie_fit = pipeline.fit(Train)\n",
    "Train=pipelie_fit.transform(Train)\n",
    "Test=pipelie_fit.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble the vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"asin_index\",\"brand_index\",\"overall\",\"price_index\",\"reviewerID_index\",\"reviewer_count\",\"verified\",\"features-Bert\"],\n",
    "    outputCol=\"features-all\")\n",
    "\n",
    "Train=assembler.transform(Train)\n",
    "Test=assembler.transform(Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC,LogisticRegression,FMClassifier,RandomForestClassifier,LinearSVC\n",
    "#initiate logistic regression with weight\n",
    "lr = LogisticRegression(featuresCol = 'features-all', \n",
    "                        labelCol = 'label', \n",
    "                        maxIter=10)\n",
    "#fit model\n",
    "lrModel = lr.fit(Train)\n",
    "prediction = lrModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722128</td>\n",
       "      <td>0.85307</td>\n",
       "      <td>0.823359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0  0.722128    0.85307   0.823359"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"label\", \n",
    "                            featuresCol=\"features-all\")\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(Train)\n",
    "prediction=lsvcModel.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.71897</td>\n",
       "      <td>0.862425</td>\n",
       "      <td>0.808473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0   0.71897   0.862425   0.808473"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization machines classifier + balanced Bert additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import FMClassifier\n",
    "fm = FMClassifier(featuresCol=\"features-all\",labelCol=\"label\",stepSize=0.001)\n",
    "# train the model\n",
    "model_fm = fm.fit(Train)\n",
    "# select example rows to display.\n",
    "prediction = model_fm.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.510809</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.992287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0  0.510809   0.099046   0.992287"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest + balanced Bert additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features-all\", \\\n",
    "                            numTrees = 50, \\\n",
    "                            maxDepth = 3, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# add training dataset\n",
    "rfModel = rf.fit(Train)\n",
    "\n",
    "prediction = rfModel.transform(Test)\n",
    "\n",
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate logistic regression with weight\n",
    "lr = LogisticRegression(featuresCol = 'features-GloVe', \n",
    "                        labelCol = 'label', \n",
    "                        maxIter=10)\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features-GloVe\", \\\n",
    "                            numTrees = 50, \\\n",
    "                            maxDepth = 3, \\\n",
    "                            maxBins = 32)\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"label\", \n",
    "                            featuresCol=\"features-GloVe\")\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features-GloVe\", maxIter=5)\n",
    "fm = FMClassifier(featuresCol=\"features-GloVe\",labelCol=\"label\",stepSize=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644596</td>\n",
       "      <td>0.834400</td>\n",
       "      <td>0.726525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.667965</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.774939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.637780</td>\n",
       "      <td>0.892063</td>\n",
       "      <td>0.633650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.662610</td>\n",
       "      <td>0.816280</td>\n",
       "      <td>0.776428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.684275</td>\n",
       "      <td>0.867496</td>\n",
       "      <td>0.749457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0  0.644596   0.834400   0.726525\n",
       "0  0.667965   0.824916   0.774939\n",
       "0  0.637780   0.892063   0.633650\n",
       "0  0.662610   0.816280   0.776428\n",
       "0  0.684275   0.867496   0.749457"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "summary=pd.DataFrame(columns=['accuracy','f1_class1','f1_class0'])\n",
    "for i in [lr,rf,lsvc,gbt,fm]:\n",
    "    model = i.fit(Train)\n",
    "    prediction = model.transform(Test)\n",
    "    results=evaluation_report(prediction)\n",
    "    summary=summary.append(results)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest + Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "numFolds = 3\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features-Bert\")\n",
    "evaluator = MulticlassClassificationEvaluator() \n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(rf.numTrees, [100,150]) \\\n",
    "             .addGrid(rf.maxDepth, [5,6,7]) \\\n",
    "             .build())\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=numFolds)\n",
    "\n",
    "model = crossval.fit(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.721642</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.859797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0  0.721642   0.816742   0.859797"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "numFolds = 3\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features-Bert\", maxIter=30)\n",
    "evaluator = MulticlassClassificationEvaluator() \n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(gbt.stepSize, [0.1,0.01,0.05]) \\\n",
    "             .addGrid(gbt.maxDepth, [10,15]) \\\n",
    "             .build())\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=numFolds)\n",
    "\n",
    "model = crossval.fit(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(Test)\n",
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "numFolds = 3\n",
    "\n",
    "lr = LogisticRegression(featuresCol = 'features-Bert', \n",
    "                        labelCol = 'label', \n",
    "                        maxIter=10)\n",
    "evaluator = MulticlassClassificationEvaluator() \n",
    "\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(lr.regParam, [0.1,0.01,0.05]) \\\n",
    "             .addGrid(lr.elasticNetParam, [0.01,0.05]) \\\n",
    "             .addGrid(lr.threshold, [0.4,0.5,0.6]) \\\n",
    "             .build())\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=numFolds)\n",
    "\n",
    "model = crossval.fit(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722053</td>\n",
       "      <td>0.828891</td>\n",
       "      <td>0.848122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0  0.722053   0.828891   0.848122"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.transform(Test)\n",
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_class0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.709419</td>\n",
       "      <td>0.820769</td>\n",
       "      <td>0.838976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_class1  f1_class0\n",
       "0  0.709419   0.820769   0.838976"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numFolds = 3\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"label\", \n",
    "                            featuresCol=\"features-Bert\")\n",
    "evaluator = MulticlassClassificationEvaluator() \n",
    "\n",
    "pipeline = Pipeline(stages=[lsvc])\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(lsvc.maxIter, [10,20]) \\\n",
    "             .addGrid(lsvc.regParam, [0.1,0.2,0.3]) \\\n",
    "             .build())\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=numFolds)\n",
    "\n",
    "model = crossval.fit(Train)\n",
    "prediction = model.transform(Test)\n",
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFolds = 3\n",
    "\n",
    "fm = FMClassifier(featuresCol=\"features-Bert\",labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator() \n",
    "\n",
    "pipeline = Pipeline(stages=[fm])\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(fm.factorSize, [10,15]) \\\n",
    "             .addGrid(fm.stepSize,[1,0.5,1.5]) \\\n",
    "             .build())\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=numFolds)\n",
    "\n",
    "model = crossval.fit(Train)\n",
    "prediction = model.transform(Test)\n",
    "results=evaluation_report(prediction)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "39f583f7-cd88-4d53-af07-5962b7ec2be7",
    "6243e941-8563-410c-b657-0b9249e8c1ed",
    "fc9b90f8-5f09-4225-b565-2cfe90653636",
    "f3d2d866-8cb9-4572-b242-c2f6c26cee6a",
    "563070a3-4100-4655-b323-80a8e440765f",
    "459c9c53-17bb-41e3-b40d-6a3e79dd6472",
    "b6ceb708-509e-4d63-a00d-143cbc5a7c88",
    "8a6745b2-d260-4a94-a50f-2119e07ae7c3"
   ],
   "name": "predict_helpful (5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
