{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start instance, read in libraries, and change configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id, lower\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#create Spark session\n",
    "spark = SparkSession.builder.appName('BDLDA').getOrCreate()\n",
    "\n",
    "# Change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'), \\\n",
    "                                        ('spark.executor.memoryOverhead', '8g'), \\\n",
    "                                        ('spark.app.name', 'Spark Updated Conf'), \\\n",
    "                                        ('spark.executor.cores', '8'), \\\n",
    "                                        ('spark.cores.max', '4'), \\\n",
    "                                        ('spark.driver.memory','4g')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "df_lda = spark.read.json(\"gs://bdprojectfinal/df_full_feature_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "df_lda = df_lda.drop(\"Year\", \"also_buy\", \"also_view\", \"category\", \"description\", \"details\", \"fit\", \\\n",
    "                     \"main_cat\", \"rank\", \"reviewTime\", \"reviewerID\", \"reviewerName\", \\\n",
    "                     \"summary\", \"title\", \"unixReviewTime\", \"verified\", \"vote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- feature: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lda.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls\n",
    "df_lda = df_lda.where(col(\"reviewText\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set reviewText to lowercase\n",
    "df_lda = df_lda.withColumn('reviewText', lower(col('reviewText')))\n",
    "\n",
    "# Separate based on rating\n",
    "df_lda1 = df_lda.filter(df_lda.overall.isin(1))\n",
    "df_lda2 = df_lda.filter(df_lda.overall.isin(2))\n",
    "df_lda3 = df_lda.filter(df_lda.overall.isin(3))\n",
    "df_lda4 = df_lda.filter(df_lda.overall.isin(4))\n",
    "df_lda5 = df_lda.filter(df_lda.overall.isin(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tokenizer, remover, CV, and assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(inputCol = \"filtered\", outputCol = \"features\")\n",
    "assembler = VectorAssembler(inputCols = [\"features\"], outputCol = \"vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda1 = tokenizer.transform(df_lda1) #tokenize\n",
    "df_lda1 = remover.transform(df_lda1) #remove stopwords\n",
    "df_lda1 = df_lda1.drop(\"words\") #drop redundant source column\n",
    "df_lda1 = df_lda1.drop(\"overall\") #drop rating column\n",
    "cv1 = cv.fit(df_lda1)\n",
    "df_lda1 = cv1.transform(df_lda1) #CV\n",
    "df_lda1 = df_lda1.where(col(\"features\").isNotNull()) #drop any rows with no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda2 = tokenizer.transform(df_lda2) #tokenize\n",
    "df_lda2 = remover.transform(df_lda2) #remove stopwords\n",
    "df_lda2 = df_lda2.drop(\"words\") #drop redundant source column\n",
    "df_lda2 = df_lda2.drop(\"overall\") #drop rating column\n",
    "cv2 = cv.fit(df_lda2)\n",
    "df_lda2 = cv2.transform(df_lda2) #CV\n",
    "df_lda2 = df_lda2.where(col(\"features\").isNotNull()) #drop any rows with no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda3 = tokenizer.transform(df_lda3) #tokenize\n",
    "df_lda3 = remover.transform(df_lda3) #remove stopwords\n",
    "df_lda3 = df_lda3.drop(\"words\") #drop redundant source column\n",
    "df_lda3 = df_lda3.drop(\"overall\") #drop rating column\n",
    "cv3 = cv.fit(df_lda3)\n",
    "df_lda3 = cv3.transform(df_lda3) #CV\n",
    "df_lda3 = df_lda3.where(col(\"features\").isNotNull()) #drop any rows with no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda4 = tokenizer.transform(df_lda4) #tokenize\n",
    "df_lda4 = remover.transform(df_lda4) #remove stopwords\n",
    "df_lda4 = df_lda4.drop(\"words\") #drop redundant source column\n",
    "df_lda4 = df_lda4.drop(\"overall\") #drop rating column\n",
    "cv4 = cv.fit(df_lda4)\n",
    "df_lda4 = cv4.transform(df_lda4) #CV\n",
    "df_lda4 = df_lda4.where(col(\"features\").isNotNull()) #drop any rows with no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda5 = tokenizer.transform(df_lda5) #tokenize\n",
    "df_lda5 = remover.transform(df_lda5) #remove stopwords\n",
    "df_lda5 = df_lda5.drop(\"words\") #drop redundant source column\n",
    "df_lda5 = df_lda5.drop(\"overall\") #drop rating column\n",
    "cv5 = cv.fit(df_lda5)\n",
    "df_lda5 = cv5.transform(df_lda5) #CV\n",
    "df_lda5 = df_lda5.where(col(\"features\").isNotNull()) #drop any rows with no features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedDataCV1 = assembler.transform(df_lda1)\n",
    "encodedDataCV2 = assembler.transform(df_lda2)\n",
    "encodedDataCV3 = assembler.transform(df_lda3)\n",
    "encodedDataCV4 = assembler.transform(df_lda4)\n",
    "encodedDataCV5 = assembler.transform(df_lda5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab1 = cv1.vocabulary\n",
    "vocab2 = cv2.vocabulary\n",
    "vocab3 = cv3.vocabulary\n",
    "vocab4 = cv4.vocabulary\n",
    "vocab5 = cv5.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/ml-clustering.html#latent-dirichlet-allocation-lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define settings for LDA\n",
    "num_topics = 5\n",
    "max_iterations = 10 #default 20\n",
    "seed_num = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LDA model\n",
    "lda1 = LDA(k = num_topics, maxIter = max_iterations)\n",
    "model1 = lda1.fit(encodedDataCV1).setSeed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LDA model\n",
    "lda2 = LDA(k = num_topics, maxIter = max_iterations)\n",
    "model2 = lda2.fit(encodedDataCV2).setSeed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LDA model\n",
    "lda3 = LDA(k = num_topics, maxIter = max_iterations)\n",
    "model3 = lda3.fit(encodedDataCV3).setSeed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LDA model\n",
    "lda4 = LDA(k = num_topics, maxIter = max_iterations)\n",
    "model4 = lda4.fit(encodedDataCV4).setSeed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LDA model\n",
    "lda5 = LDA(k = num_topics, maxIter = max_iterations)\n",
    "model5 = lda5.fit(encodedDataCV5).setSeed(seed_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at results of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices                          |termWeights                                                                                                                                                                                                                      |\n",
      "+-----+-------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[3, 2, 7, 1, 4, 5, 8, 16, 18, 9]     |[0.010383823694035992, 0.009801416884523788, 0.008655418909221531, 0.008527397447768273, 0.007812466875563925, 0.0058831989930246955, 0.005849382247819017, 0.00459259784792397, 0.004409445192709866, 0.0042498386900971415]    |\n",
      "|1    |[0, 2, 1, 13, 4, 5, 6, 11, 9, 12]    |[0.046160192681092706, 0.008827515146081613, 0.005784027543022072, 0.005697740947659684, 0.004821411409879191, 0.004641095666593974, 0.004592258029891582, 0.004492884651401348, 0.004481203551863414, 0.004190102147750996]     |\n",
      "|2    |[0, 1, 31, 14, 19, 3, 6, 52, 5, 10]  |[0.005789622913147224, 0.0028292265445404754, 0.002447636968342033, 0.002183512965840464, 0.002091301356016119, 0.0020617943784352675, 0.0020257649189527323, 0.0017452045171970627, 0.001564407890763271, 0.0015638037342460265]|\n",
      "|3    |[0, 1, 3, 14, 25, 7, 10, 44, 42, 66] |[0.0016930780775501067, 0.0011857779476072583, 0.001171382053997073, 0.001013034028192521, 6.409387064259198E-4, 5.716818383651706E-4, 5.520405897751501E-4, 5.361127360401106E-4, 5.286925679505916E-4, 5.167283087166962E-4]   |\n",
      "|4    |[0, 1, 14, 11, 32, 6, 50, 75, 20, 47]|[0.01648072284613951, 0.012051804568941008, 0.004987724834369634, 0.004586075125610043, 0.004195485013349681, 0.003728768960941271, 0.00349356335633459, 0.003466118859584676, 0.0034242666060340815, 0.003260241002625926]      |\n",
      "+-----+-------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "# Returns DF that has mapping of term weights to term indices for each topic: https://stackoverflow.com/questions/49613772/get-automatic-topic-labels-from-lda-topic-model-in-apache-spark\n",
    "\n",
    "#model1.describeTopics(maxTermsPerTopic = 15).show(truncate = False)\n",
    "\n",
    "topics1 = model1.describeTopics()\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices                        |termWeights                                                                                                                                                                                                                         |\n",
      "+-----+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[3, 1, 4, 2, 9, 19, 18, 16, 37, 61]|[0.003808405425328728, 0.003475444028127159, 0.002547181772838547, 0.002350110708034457, 0.0021150945911021382, 0.0018737077401784026, 0.0016125677709777017, 0.001451057200496523, 0.0014380735951379953, 0.0014017469885881915]   |\n",
      "|1    |[0, 1, 2, 3, 4, 6, 5, 7, 8, 9]     |[0.02765002933786161, 0.010217455531196682, 0.009512053921057334, 0.007824864547242788, 0.005925923193426521, 0.005672129089640057, 0.0055064779360129296, 0.004928373493900345, 0.004718332668331982, 0.00433905968196124]         |\n",
      "|2    |[0, 1, 3, 2, 22, 8, 1656, 20, 5, 4]|[0.0020166624335573014, 0.0015676965777255895, 0.001411733559724582, 0.0013977495496667138, 6.833296204932296E-4, 6.618302107136579E-4, 6.496824698143694E-4, 6.333722639548883E-4, 6.326325277834438E-4, 6.250281239073717E-4]     |\n",
      "|3    |[0, 1, 7, 56, 8, 36, 2, 14, 3, 17] |[0.00296341360996204, 0.001070577134752939, 6.735630495311685E-4, 6.595200640072786E-4, 6.562502143590422E-4, 6.289144086998167E-4, 6.109096382045702E-4, 5.944888771340855E-4, 5.875313695875657E-4, 5.695094825995943E-4]         |\n",
      "|4    |[0, 1, 2, 9, 11, 5, 6, 24, 4, 3]   |[0.003044719988668038, 0.0025362195989490147, 0.0016910475927141239, 0.0011322660835306041, 0.0010885511727255768, 0.0010778904211900763, 0.0010619572325534143, 0.0010405930375464794, 0.001019534370951014, 0.0010186472962713353]|\n",
      "+-----+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "topics2 = model2.describeTopics()\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices                        |termWeights                                                                                                                                                                                                                         |\n",
      "+-----+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[1, 2, 3, 4, 0, 7, 5, 10, 9, 18]   |[0.014428795081538624, 0.012758352646239231, 0.011672549287216193, 0.008290459628116817, 0.006986561494036589, 0.006897744657147877, 0.006846986475722151, 0.006267689302107864, 0.005534405219312519, 0.004735370831766777]        |\n",
      "|1    |[0, 8, 6, 12, 14, 1, 22, 54, 2, 13]|[0.05710948153936276, 0.00706137070790777, 0.005390268215476727, 0.0043662022314783795, 0.004331640404890699, 0.003995826572896861, 0.003607163911289994, 0.003363244386874401, 0.0033533638761829073, 0.0032937684318829976]       |\n",
      "|2    |[88, 6, 0, 2, 5, 1, 8, 7, 25, 32]  |[0.0043325498276187, 0.0023705358036857525, 0.0022425669525598267, 0.002025114471451155, 0.0016808179582776886, 0.0014153114741074213, 0.0012326779762904668, 0.0011265714995692515, 9.92342691383504E-4, 9.87575994366143E-4]      |\n",
      "|3    |[0, 1, 3, 2, 8, 5, 20, 48, 17, 6]  |[0.004293526933991553, 0.0036145816675437485, 0.0024035898652695503, 0.0015234518994956918, 0.0014629109942073213, 0.0014528437387287113, 0.0013695538109390272, 0.0012234999752554646, 0.0012048616035998734, 0.001042610159938627]|\n",
      "|4    |[0, 11, 2, 5, 27, 6, 9, 7, 16, 17] |[0.01396519997538001, 0.0066787636750240045, 0.0064440863084068685, 0.0037018743278292086, 0.00357305896291984, 0.0033883582387154716, 0.003381898898432391, 0.003130014878377917, 0.002791399552594389, 0.0027323141038184087]     |\n",
      "+-----+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "topics3 = model3.describeTopics()\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices                        |termWeights                                                                                                                                                                                                                      |\n",
      "+-----+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[2, 4, 3, 1, 9, 6, 7, 0, 5, 8]     |[0.01430790902945976, 0.013335805892846641, 0.0120635379700435, 0.009412660684668459, 0.008648110109098503, 0.007746329330338398, 0.007476238446375103, 0.00735149947591706, 0.007115052764230808, 0.006801159609781767]         |\n",
      "|1    |[0, 6, 7, 139, 2, 4, 5, 30, 19, 12]|[0.017269551915464847, 0.007035288918040544, 0.006247817352444503, 0.006050590422548581, 0.0051293926244212066, 0.0034619426135778543, 0.0030875556905506003, 0.0020841647008859984, 0.002021781265475835, 0.0018896709321493256]|\n",
      "|2    |[0, 5, 1, 6, 3, 8, 7, 23, 16, 11]  |[0.04118800788767248, 0.0105503652646322, 0.010102533788332339, 0.006240486423952278, 0.006088726985019157, 0.005532549047867428, 0.005319093297352988, 0.005316429497405092, 0.005165973531949602, 0.004907713627858081]        |\n",
      "|3    |[1, 0, 6, 7, 5, 3, 9, 4, 13, 17]   |[0.006617343969243025, 0.00572688769910807, 0.00225299134372947, 0.0020404548275490563, 0.0020348593716000563, 0.0018339920457434227, 0.0018138202115155861, 0.0017969773045724065, 0.0016906271577253197, 0.0016745815672701873]|\n",
      "|4    |[2, 0, 9, 3, 8, 1, 6, 14, 10, 15]  |[0.005496695086038188, 0.005360554009083808, 0.005348845891222888, 0.005056238272004791, 0.0036266174726804186, 0.0035724907849462697, 0.003074071861782559, 0.0029232606524118914, 0.0026022838829039014, 0.0018712009690705989]|\n",
      "+-----+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "topics4 = model4.describeTopics()\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices                         |termWeights                                                                                                                                                                                                                      |\n",
      "+-----+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[2, 19, 4, 3, 27, 18, 12, 1, 67, 98]|[0.04057304126496658, 0.02271974158678895, 0.021291487298591562, 0.015264697175333177, 0.013187545605809476, 0.010357468841279827, 0.00855046324030598, 0.006758303720416789, 0.006748600934921878, 0.005911325755854275]        |\n",
      "|1    |[0, 1, 2, 5, 7, 6, 3, 12, 16, 11]   |[0.03021718822452755, 0.01958833487012624, 0.011102049339633767, 0.008417836028293924, 0.008401940347755295, 0.008182322024487099, 0.007976002789784229, 0.005184477572049458, 0.005124204128331143, 0.004929199817454472]       |\n",
      "|2    |[0, 3, 10, 1, 8, 2, 4, 14, 9, 11]   |[0.03162851363850184, 0.021285730698310638, 0.01878622153502356, 0.01510341730496958, 0.014751570087963524, 0.013629493165892079, 0.01250486532733949, 0.011720990864904768, 0.011690436580558612, 0.010060713812048037]         |\n",
      "|3    |[2, 14, 27, 522, 8, 4, 0, 3, 5, 45] |[0.0063915842931830235, 0.005324003992515527, 0.004688997454356331, 0.004192066852970436, 0.00372332651507157, 0.0034273752866755556, 0.0031785872441289363, 0.0028438573032722207, 0.0024657868231665117, 0.0022344804819038806]|\n",
      "|4    |[0, 5, 9, 1, 86, 19, 77, 10, 2, 3]  |[0.01578551948616519, 0.009645290483985675, 0.008546060393721735, 0.0068396053326736286, 0.004710647589474584, 0.0038890693911920408, 0.0038525312014119307, 0.003589568089156808, 0.0030066022690052557, 0.0028149659113464046] |\n",
      "+-----+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "topics5 = model5.describeTopics()\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics5.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up values in dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|termIndices                          |\n",
      "+-------------------------------------+\n",
      "|[3, 2, 7, 1, 4, 5, 8, 16, 18, 9]     |\n",
      "|[0, 2, 1, 13, 4, 5, 6, 11, 9, 12]    |\n",
      "|[0, 1, 31, 14, 19, 3, 6, 52, 5, 10]  |\n",
      "|[0, 1, 3, 14, 25, 7, 10, 44, 42, 66] |\n",
      "|[0, 1, 14, 11, 32, 6, 50, 75, 20, 47]|\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show only the indices\n",
    "t1indices = topics1.select('termIndices')\n",
    "t1indices.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save indices as separate vectors\n",
    "t1indices0 = [3, 2, 7, 1, 4, 5, 8, 16, 18, 9]\n",
    "t1indices1 = [0, 2, 1, 13, 4, 5, 6, 11, 9, 12]\n",
    "t1indices2 = [0, 1, 31, 14, 19, 3, 6, 52, 5, 10]\n",
    "t1indices3 = [0, 1, 3, 14, 25, 7, 10, 44, 42, 66]\n",
    "t1indices4 = [0, 1, 14, 11, 32, 6, 50, 75, 20, 47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "size\n",
      "small\n",
      "like\n",
      "fit\n",
      "ordered\n",
      "way\n",
      "first\n",
      "time\n",
      "wear\n"
     ]
    }
   ],
   "source": [
    "for i in t1indices0:\n",
    "    print(vocab1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "size\n",
      "like\n",
      "return\n",
      "fit\n",
      "ordered\n",
      "even\n",
      "shoes\n",
      "wear\n",
      "get\n"
     ]
    }
   ],
   "source": [
    "for i in t1indices1:\n",
    "    print(vocab1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "product\n",
      "quality\n",
      "cheap\n",
      "one\n",
      "even\n",
      "see\n",
      "ordered\n",
      "bought\n"
     ]
    }
   ],
   "source": [
    "for i in t1indices2:\n",
    "    print(vocab1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "one\n",
      "quality\n",
      "received\n",
      "small\n",
      "bought\n",
      "returned\n",
      "big\n",
      "fell\n"
     ]
    }
   ],
   "source": [
    "for i in t1indices3:\n",
    "    print(vocab1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "quality\n",
      "shoes\n",
      "looks\n",
      "even\n",
      "poor\n",
      "quality.\n",
      "buy\n",
      "waste\n"
     ]
    }
   ],
   "source": [
    "for i in t1indices4:\n",
    "    print(vocab1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|termIndices                        |\n",
      "+-----------------------------------+\n",
      "|[3, 1, 4, 2, 9, 19, 18, 16, 37, 61]|\n",
      "|[0, 1, 2, 3, 4, 6, 5, 7, 8, 9]     |\n",
      "|[0, 1, 3, 2, 22, 8, 1656, 20, 5, 4]|\n",
      "|[0, 1, 7, 56, 8, 36, 2, 14, 3, 17] |\n",
      "|[0, 1, 2, 9, 11, 5, 6, 24, 4, 3]   |\n",
      "+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show only the indices\n",
    "t2indices = topics2.select('termIndices')\n",
    "t2indices.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save indices as separate vectors\n",
    "t2indices0 = [3, 1, 4, 2, 9, 19, 18, 16, 37, 61]\n",
    "t2indices1 = [0, 1, 2, 3, 4, 6, 5, 7, 8, 9]\n",
    "t2indices2 = [0, 1, 3, 2, 22, 8, 1656, 20, 5, 4]\n",
    "t2indices3 = [0, 1, 7, 56, 8, 36, 2, 14, 3, 17]\n",
    "t2indices4 = [0, 1, 2, 9, 11, 5, 6, 24, 4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "like\n",
      "one\n",
      "size\n",
      "really\n",
      "shoe\n",
      "material\n",
      "look\n",
      "big\n",
      "dress\n"
     ]
    }
   ],
   "source": [
    "for i in t2indices0:\n",
    "    print(vocab2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "size\n",
      "fit\n",
      "one\n",
      "small\n",
      "wear\n",
      "way\n",
      "ordered\n",
      "really\n"
     ]
    }
   ],
   "source": [
    "for i in t2indices1:\n",
    "    print(vocab2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "fit\n",
      "size\n",
      "much\n",
      "ordered\n",
      "la\n",
      "small.\n",
      "wear\n",
      "one\n"
     ]
    }
   ],
   "source": [
    "for i in t2indices2:\n",
    "    print(vocab2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "way\n",
      "-\n",
      "ordered\n",
      "little\n",
      "size\n",
      "quality\n",
      "fit\n",
      "it.\n"
     ]
    }
   ],
   "source": [
    "for i in t2indices3:\n",
    "    print(vocab2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "size\n",
      "really\n",
      "shoes\n",
      "wear\n",
      "small\n",
      "return\n",
      "one\n",
      "fit\n"
     ]
    }
   ],
   "source": [
    "for i in t2indices4:\n",
    "    print(vocab2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|termIndices                        |\n",
      "+-----------------------------------+\n",
      "|[1, 2, 3, 4, 0, 7, 5, 10, 9, 18]   |\n",
      "|[0, 8, 6, 12, 14, 1, 22, 54, 2, 13]|\n",
      "|[88, 6, 0, 2, 5, 1, 8, 7, 25, 32]  |\n",
      "|[0, 1, 3, 2, 8, 5, 20, 48, 17, 6]  |\n",
      "|[0, 11, 2, 5, 27, 6, 9, 7, 16, 17] |\n",
      "+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show only the indices\n",
    "t3indices = topics3.select('termIndices')\n",
    "t3indices.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save indices as separate vectors\n",
    "t3indices0 = [1, 2, 3, 4, 0, 7, 5, 10, 9, 18]\n",
    "t3indices1 = [0, 8, 6, 12, 14, 1, 22, 54, 2, 13]\n",
    "t3indices2 = [88, 6, 0, 2, 5, 1, 8, 7, 25, 32]\n",
    "t3indices3 = [0, 1, 3, 2, 8, 5, 20, 48, 17, 6]\n",
    "t3indices4 = [0, 11, 2, 5, 27, 6, 9, 7, 16, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\n",
      "like\n",
      "fit\n",
      "wear\n",
      "\n",
      "small\n",
      "little\n",
      "ordered\n",
      "really\n",
      "way\n"
     ]
    }
   ],
   "source": [
    "for i in t3indices0:\n",
    "    print(vocab3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "one\n",
      "good\n",
      "get\n",
      "quality\n",
      "size\n",
      "it.\n",
      "first\n",
      "like\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "for i in t3indices1:\n",
    "    print(vocab3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "good\n",
      "\n",
      "like\n",
      "little\n",
      "size\n",
      "one\n",
      "small\n",
      "color\n",
      "looks\n"
     ]
    }
   ],
   "source": [
    "for i in t3indices2:\n",
    "    print(vocab3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "size\n",
      "fit\n",
      "like\n",
      "one\n",
      "little\n",
      "love\n",
      "shirt\n",
      "material\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "for i in t3indices3:\n",
    "    print(vocab3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nice\n",
      "like\n",
      "little\n",
      "much\n",
      "good\n",
      "really\n",
      "small\n",
      "look\n",
      "material\n"
     ]
    }
   ],
   "source": [
    "for i in t3indices4:\n",
    "    print(vocab3[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|termIndices                        |\n",
      "+-----------------------------------+\n",
      "|[2, 4, 3, 1, 9, 6, 7, 0, 5, 8]     |\n",
      "|[0, 6, 7, 139, 2, 4, 5, 30, 19, 12]|\n",
      "|[0, 5, 1, 6, 3, 8, 7, 23, 16, 11]  |\n",
      "|[1, 0, 6, 7, 5, 3, 9, 4, 13, 17]   |\n",
      "|[2, 0, 9, 3, 8, 1, 6, 14, 10, 15]  |\n",
      "+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show only the indices\n",
    "t4indices = topics4.select('termIndices')\n",
    "t4indices.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save indices as separate vectors\n",
    "t4indices0 = [2, 4, 3, 1, 9, 6, 7, 0, 5, 8]\n",
    "t4indices1 = [0, 6, 7, 139, 2, 4, 5, 30, 19, 12]\n",
    "t4indices2 = [0, 5, 1, 6, 3, 8, 7, 23, 16, 11]\n",
    "t4indices3 = [1, 0, 6, 7, 5, 3, 9, 4, 13, 17]\n",
    "t4indices4 = [2, 0, 9, 3, 8, 1, 6, 14, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\n",
      "little\n",
      "fit\n",
      "like\n",
      "love\n",
      "great\n",
      "nice\n",
      "\n",
      "good\n",
      "wear\n"
     ]
    }
   ],
   "source": [
    "for i in t4indices0:\n",
    "    print(vocab4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "great\n",
      "nice\n",
      "watch\n",
      "size\n",
      "little\n",
      "good\n",
      "big\n",
      "quality\n",
      "one\n"
     ]
    }
   ],
   "source": [
    "for i in t4indices1:\n",
    "    print(vocab4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "good\n",
      "like\n",
      "great\n",
      "fit\n",
      "wear\n",
      "nice\n",
      "shoes\n",
      "well\n",
      "really\n"
     ]
    }
   ],
   "source": [
    "for i in t4indices2:\n",
    "    print(vocab4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n",
      "\n",
      "great\n",
      "nice\n",
      "good\n",
      "fit\n",
      "love\n",
      "little\n",
      "fits\n",
      "small\n"
     ]
    }
   ],
   "source": [
    "for i in t4indices3:\n",
    "    print(vocab4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\n",
      "\n",
      "love\n",
      "fit\n",
      "wear\n",
      "like\n",
      "great\n",
      "ordered\n",
      "bit\n",
      "comfortable\n"
     ]
    }
   ],
   "source": [
    "for i in t4indices4:\n",
    "    print(vocab4[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|termIndices                         |\n",
      "+------------------------------------+\n",
      "|[2, 19, 4, 3, 27, 18, 12, 1, 67, 98]|\n",
      "|[0, 1, 2, 5, 7, 6, 3, 12, 16, 11]   |\n",
      "|[0, 3, 10, 1, 8, 2, 4, 14, 9, 11]   |\n",
      "|[2, 14, 27, 522, 8, 4, 0, 3, 5, 45] |\n",
      "|[0, 5, 9, 1, 86, 19, 77, 10, 2, 3]  |\n",
      "+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show only the indices\n",
    "t5indices = topics5.select('termIndices')\n",
    "t5indices.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save indices as separate vectors\n",
    "t5indices0 = [2, 19, 4, 3, 27, 18, 12, 1, 67, 98]\n",
    "t5indices1 = [0, 1, 2, 5, 7, 6, 3, 12, 16, 11]\n",
    "t5indices2 = [0, 3, 10, 1, 8, 2, 4, 14, 9, 11]\n",
    "t5indices3 = [2, 14, 27, 522, 8, 4, 0, 3, 5, 45]\n",
    "t5indices4 = [0, 5, 9, 1, 86, 19, 77, 10, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "loves\n",
      "good\n",
      "fit\n",
      "loved\n",
      "it.\n",
      "bought\n",
      "love\n",
      "daughter\n",
      "son\n"
     ]
    }
   ],
   "source": [
    "for i in t5indices0:\n",
    "    print(vocab5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "love\n",
      "great\n",
      "like\n",
      "wear\n",
      "size\n",
      "fit\n",
      "bought\n",
      "one\n",
      "fits\n"
     ]
    }
   ],
   "source": [
    "for i in t5indices1:\n",
    "    print(vocab5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit\n",
      "nice\n",
      "love\n",
      "perfect\n",
      "great\n",
      "good\n",
      "quality\n",
      "comfortable\n",
      "fits\n"
     ]
    }
   ],
   "source": [
    "for i in t5indices2:\n",
    "    print(vocab5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "quality\n",
      "loved\n",
      "described\n",
      "perfect\n",
      "good\n",
      "\n",
      "fit\n",
      "like\n",
      "exactly\n"
     ]
    }
   ],
   "source": [
    "for i in t5indices3:\n",
    "    print(vocab5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like\n",
      "comfortable\n",
      "love\n",
      "excellent\n",
      "loves\n",
      "husband\n",
      "nice\n",
      "great\n",
      "fit\n"
     ]
    }
   ],
   "source": [
    "for i in t5indices4:\n",
    "    print(vocab5[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|      brand|             feature|           price|          reviewText|            filtered|            features|             vectors|   topicDistribution|\n",
      "+----------+-----------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|B0001YRW3I|       null|[100% cotton, Pac...|            null|   did not like them|              [like]|  (124872,[1],[1.0])|  (124872,[1],[1.0])|[0.10992527110721...|\n",
      "|B0002M9DO0|STABILicers|[MAXX: Winter can...|$34.99 - $101.79|size is way off t...|   [size, way, fit!]|(124872,[2,8,1992...|(124872,[2,8,1992...|[0.81431960889390...|\n",
      "|B0003DKV80|      Perry|[Elastic, Made in...| $11.29 - $16.76|not tall. tried t...|[tall., tried, tw...|(124872,[6,12,17,...|(124872,[6,12,17,...|[0.93861272013434...|\n",
      "|B000783NRW|       null|[80% Cotton, 20% ...| $42.95 - $47.95|ordered a 5x and ...|[ordered, 5x, lik...|(124872,[1,5,53,2...|(124872,[1,5,53,2...|[0.85194902972770...|\n",
      "|B000794186|     Rothco|[100% Polyester, ...| $12.99 - $21.24|its a very cheap ...|[cheap, nylon, te...|(124872,[6,8,19,4...|(124872,[6,8,19,4...|[0.94311004793884...|\n",
      "+----------+-----------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the result\n",
    "# Shows the weight for each topic\n",
    "transformed1 = model1.transform(encodedDataCV1)\n",
    "transformed1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|      brand|             feature|           price|          reviewText|            filtered|            features|             vectors|   topicDistribution|\n",
      "+----------+-----------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|6030555170|  Lady olga|[100% Polyester, ...| $26.80 - $26.94|definitely too sm...|[definitely, smal...|(99842,[3,6,24,85...|(99842,[3,6,24,85...|[0.00686013754254...|\n",
      "|B0000WL750|       null|[100% Cotton, Imp...|$54.99 - $104.67|after a few washi...|[washings, leg, s...|(99842,[76,120,15...|(99842,[76,120,15...|[0.00960849801255...|\n",
      "|B0002M9DO0|STABILicers|[MAXX: Winter can...|$34.99 - $101.79|work really well....|[work, really, we...|(99842,[9,23,27,6...|(99842,[9,23,27,6...|[0.00752931301666...|\n",
      "|B0002M9DO0|STABILicers|[MAXX: Winter can...|$34.99 - $101.79|ordered a size xx...|[ordered, size, x...|(99842,[2,3,5,8,1...|(99842,[2,3,5,8,1...|[0.00372975085551...|\n",
      "|B0002M9DO0|STABILicers|[MAXX: Winter can...|$34.99 - $101.79|the sole and spik...|[sole, spikes, wo...|(99842,[0,3,9,38,...|(99842,[0,3,9,38,...|[0.00245212709267...|\n",
      "+----------+-----------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed2 = model2.transform(encodedDataCV2)\n",
    "transformed2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|brand|             feature|           price|          reviewText|            filtered|            features|             vectors|   topicDistribution|\n",
      "+----------+-----+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|B0000WL750| null|[100% Cotton, Imp...|$54.99 - $104.67|order 2 sizes lar...|[order, 2, sizes,...|(123526,[4,49,73,...|(123526,[4,49,73,...|[0.88002741566708...|\n",
      "|B0000WL750| null|[100% Cotton, Imp...|$54.99 - $104.67|carhartt has alwa...|[carhartt, always...|(123526,[3,6,13,2...|(123526,[3,6,13,2...|[0.98062815965508...|\n",
      "|B0000WL750| null|[100% Cotton, Imp...|$54.99 - $104.67|fits well as long...|[fits, well, long...|(123526,[0,2,16,3...|(123526,[0,2,16,3...|[0.60707282594841...|\n",
      "|B0002M4VBA| null|[100% Cotton, Imp...| $42.24 - $69.95|the holes that th...|[holes, side, \"bu...|(123526,[3,34,141...|(123526,[3,34,141...|[0.01742253290989...|\n",
      "|B000783NRW| null|[80% Cotton, 20% ...| $42.95 - $47.95|size runs a bit s...|[size, runs, bit,...|(123526,[1,15,17,...|(123526,[1,15,17,...|[0.32081482045325...|\n",
      "+----------+-----+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed3 = model3.transform(encodedDataCV3)\n",
    "transformed3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|    brand|             feature|           price|          reviewText|            filtered|            features|             vectors|   topicDistribution|\n",
      "+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|6030555170|Lady olga|[100% Polyester, ...| $26.80 - $26.94|           i love it|              [love]|  (167604,[9],[1.0])|  (167604,[9],[1.0])|[0.62690480734490...|\n",
      "|B00001OGXK|     null|[Glass, This Aust...|            null|did the job. won ...|[job., won, first...|(167604,[71,501,5...|(167604,[71,501,5...|[0.89570390469220...|\n",
      "|B0000WL750|     null|[100% Cotton, Imp...|$54.99 - $104.67|great product. i ...|[great, product.,...|(167604,[3,6,8,18...|(167604,[3,6,8,18...|[0.95971429254605...|\n",
      "|B0000WL750|     null|[100% Cotton, Imp...|$54.99 - $104.67|that they got goo...|[got, good, comfo...|(167604,[5,25,45]...|(167604,[5,25,45]...|[0.81605818463085...|\n",
      "|B0000WL750|     null|[100% Cotton, Imp...|$54.99 - $104.67|sorry for taking ...|[sorry, taking, l...|(167604,[5,7,58,1...|(167604,[5,7,58,1...|[0.95705752120916...|\n",
      "+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed4 = model4.transform(encodedDataCV4)\n",
    "transformed4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|    brand|             feature|            price|          reviewText|            filtered|            features|             vectors|   topicDistribution|\n",
      "+----------+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|6030555170|Lady olga|[100% Polyester, ...|  $26.80 - $26.94|this bed jacket w...|[bed, jacket, wor...|(262144,[13,148,3...|(262144,[13,148,3...|[0.02099007203407...|\n",
      "|6030555170|Lady olga|[100% Polyester, ...|  $26.80 - $26.94|       mom loved it.|   [mom, loved, it.]|(262144,[18,27,51...|(262144,[18,27,51...|[0.80887541889690...|\n",
      "|B0000E02V7|     null|[100% Leather, Im...|$107.94 - $188.00|nice boots as alw...|[nice, boots, alw...|(262144,[10,92,10...|(262144,[10,92,10...|[0.04748302397271...|\n",
      "|B0000WL750|     null|[100% Cotton, Imp...| $54.99 - $104.67|i'd love it if ca...|[love, carhartt, ...|(262144,[1,2,36,8...|(262144,[1,2,36,8...|[0.01569419849419...|\n",
      "|B0000WL750|     null|[100% Cotton, Imp...| $54.99 - $104.67|totally awesome p...|[totally, awesome...|(262144,[1,6,31,6...|(262144,[1,6,31,6...|[0.01250430995137...|\n",
      "+----------+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed5 = model5.transform(encodedDataCV5)\n",
    "transformed5.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
